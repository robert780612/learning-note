{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Entropy] [1]\n",
    "* [Conditional entropy] [2]\n",
    "* Mutual information\n",
    "* Cross entropy\n",
    "* Relative entropy (KL distance (Kullback-Leibler))\n",
    "\n",
    "[1]: #Entropy\n",
    "[2]: #Conditional-entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entropy of a descrete random variable X is \n",
    "\n",
    "$$H(X)=E[-\\log_{2}P(X)]=-\\sum_{i=1}^n P(x_i)\\log_2 P(x_i)$$\n",
    "\n",
    "$P$ is the probability mass function of a random variable X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why entropy needs log?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[What is the role of the logarithm in Shannon's entropy?] [1] \n",
    "\n",
    "[1]: https://stats.stackexchange.com/questions/87182/what-is-the-role-of-the-logarithm-in-shannons-entropy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H(X|Y)=E[-log_2 P(X|Y)]=-\\sum_{i,j} P(x_i, y_j)\\log_2 P(x_i|y_j)=-\\sum_{i,j} P(x_i, y_j)\\log_2 \\frac{P(x_i,y_j)}{P(y_j)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$I(X,Y)=\\sum_{i,j}P(x_i,y_j)log_2 \\frac{P(x_i,y_j)}{P(x_i)P(y_j)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Non-negative, i.e. $I(X,Y)\\ge 0$\n",
    "2. Symmetric $I(X,Y)=I(Y,X)$\n",
    "3. $H(X,Y) \\\\\n",
    "    = H(X)-H(X|Y) \\\\\n",
    "    = H(Y)-H(Y|X) \\\\\n",
    "    = H(X)+H(Y)-H(X,Y) \\\\\n",
    "    = H(X,Y)-H(Y|X)-H(X|Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "* [Wikipedia Entropy] [1] \n",
    "* [What is the role of the logarithm in Shannon's entropy?] [2]\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Mutual_information\n",
    "[2]: https://stats.stackexchange.com/questions/87182/what-is-the-role-of-the-logarithm-in-shannons-entropy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
